{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport io\nimport requests\nfrom PIL import Image\nimport pandas as pd","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-11-10T18:33:52.374326Z","iopub.execute_input":"2021-11-10T18:33:52.374987Z","iopub.status.idle":"2021-11-10T18:33:52.379655Z","shell.execute_reply.started":"2021-11-10T18:33:52.374949Z","shell.execute_reply":"2021-11-10T18:33:52.378616Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df = pd.read_csv(\"./test_clean.csv\", index_col=\"Id\")\ntest_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-11-10T18:34:01.864715Z","iopub.execute_input":"2021-11-10T18:34:01.865251Z","iopub.status.idle":"2021-11-10T18:34:02.134733Z","shell.execute_reply.started":"2021-11-10T18:34:01.865214Z","shell.execute_reply":"2021-11-10T18:34:02.133892Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image_directory_test = \"./drive/MyDrive/Factify_Images_Test/test\"\nfor n, row in test_df.iterrows():\n  test_df.iloc[n-1:n,0:1] = image_directory_test + \"/claim/\"  + str(n) + \".jpg\"\n  test_df.iloc[n-1:n,3:4] = image_directory_test + \"/document/\" + str(n) + \".jpg\"","metadata":{"execution":{"iopub.status.busy":"2021-11-10T18:34:03.131755Z","iopub.execute_input":"2021-11-10T18:34:03.132403Z","iopub.status.idle":"2021-11-10T18:34:04.173845Z","shell.execute_reply.started":"2021-11-10T18:34:03.132367Z","shell.execute_reply":"2021-11-10T18:34:04.173061Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-11-10T18:34:04.175502Z","iopub.execute_input":"2021-11-10T18:34:04.175738Z","iopub.status.idle":"2021-11-10T18:34:04.187855Z","shell.execute_reply.started":"2021-11-10T18:34:04.175707Z","shell.execute_reply":"2021-11-10T18:34:04.187216Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"category_to_ind = {\n    'Support_Multimodal':0,\n    'Support_Text':1,\n    'Insufficient_Multimodal':2,\n    'Insufficient_Text':3,\n    'Refute':4\n}\nind_to_category = {\n    0 : 'Support_Multimodal',\n    1 : 'Support_Text',\n    2 : 'Insufficient_Multimodal',\n    3 : 'Insufficient_Text',\n    4 : 'Refute'\n}","metadata":{"execution":{"iopub.status.busy":"2021-11-10T18:34:04.253555Z","iopub.execute_input":"2021-11-10T18:34:04.253869Z","iopub.status.idle":"2021-11-10T18:34:04.25851Z","shell.execute_reply.started":"2021-11-10T18:34:04.25384Z","shell.execute_reply":"2021-11-10T18:34:04.257492Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install transformers","metadata":{"execution":{"iopub.status.busy":"2021-11-10T18:34:05.398026Z","iopub.execute_input":"2021-11-10T18:34:05.398316Z","iopub.status.idle":"2021-11-10T18:34:12.753461Z","shell.execute_reply.started":"2021-11-10T18:34:05.39828Z","shell.execute_reply":"2021-11-10T18:34:12.752592Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install albumentations","metadata":{"execution":{"iopub.status.busy":"2021-11-10T17:37:24.879914Z","iopub.execute_input":"2021-11-10T17:37:24.880183Z","iopub.status.idle":"2021-11-10T17:37:32.280335Z","shell.execute_reply.started":"2021-11-10T17:37:24.880152Z","shell.execute_reply":"2021-11-10T17:37:32.279548Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import BertTokenizer, AdamW, get_linear_schedule_with_warmup\nimport os\nimport cv2\nfrom PIL import Image\nimport pdb\nimport time\nimport copy\nimport warnings\nimport random\nimport numpy as np\nimport pandas as pd\nfrom tqdm import tqdm_notebook as tqdm\nfrom torch.optim.lr_scheduler import ReduceLROnPlateau\nfrom sklearn.model_selection import train_test_split\nimport torch\nimport torch.nn as nn\nfrom torch.nn import functional as F\nimport torch.optim as optim\nimport torch.backends.cudnn as cudnn\nfrom torch.utils.data import DataLoader, Dataset, sampler\nfrom matplotlib import pyplot as plt\n#from albumentations import (HorizontalFlip,VerticalFlip,RandomScale,CenterCrop, Rotate, ShiftScaleRotate, Normalize, Resize, Compose, GaussNoise,RandomRotate90,Transpose,RandomBrightnessContrast,RandomCrop)\nfrom albumentations.pytorch import ToTensorV2\nimport albumentations as A\nimport matplotlib.image as mpi\nfrom pathlib import Path\nfrom sklearn.metrics import recall_score,f1_score\nfrom sklearn.model_selection import StratifiedKFold\nimport gc\nwarnings.filterwarnings(\"ignore\")\nseed = 53\nrandom.seed(seed)\nos.environ[\"PYTHONHASHSEED\"] = str(seed)\nnp.random.seed(seed)\ntorch.cuda.manual_seed(seed)\ntorch.backends.cudnn.deterministic = True","metadata":{"execution":{"iopub.status.busy":"2021-11-10T18:34:12.755805Z","iopub.execute_input":"2021-11-10T18:34:12.756082Z","iopub.status.idle":"2021-11-10T18:34:12.768564Z","shell.execute_reply.started":"2021-11-10T18:34:12.756046Z","shell.execute_reply":"2021-11-10T18:34:12.767336Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Dataset(Dataset):\n    def __init__(self, df, mean, std, phase):\n        self.df = df\n        self.mean = mean\n        self.std = std\n        self.phase = phase\n        self.transforms = get_transforms(phase, mean, std)\n        self.fnames = self.df.index\n        self.tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', \n                                          do_lower_case=True)\n\n    def __getitem__(self, idx):\n        # Image data\n        \n        ## Claim Image\n        image_claim_path = self.df['claim_image'].iloc[idx]\n        img_claim = cv2.imread(image_claim_path)\n        img_claim =  cv2.cvtColor(img_claim, cv2.COLOR_BGR2RGB)\n        img_claim = self.transforms(image = img_claim)['image']\n \n        ## Document Image\n        image_document_path = self.df['document_image'].iloc[idx]\n        img_document = np.array(Image.new('RGB',(256,256)))\n        img_document =  cv2.cvtColor(img_document, cv2.COLOR_BGR2RGB)\n        img_document = self.transforms(image = img_document)['image']\n\n        # Text data\n\n        ## Claim text\n        claim_text = self.df['claim'].iloc[idx]\n        if type(claim_text) != str:\n          claim_text = \" \"\n        encoded_text_claim = self.tokenizer(\n            claim_text, \n            add_special_tokens=True,\n            return_attention_mask=True, \n            pad_to_max_length=True, \n            max_length=64, \n            return_tensors='pt',\n            truncation=True\n        )\n        encoded_text_claim[\"input_ids\"] = encoded_text_claim[\"input_ids\"].squeeze(0)\n        encoded_text_claim[\"attention_mask\"] = encoded_text_claim[\"attention_mask\"].squeeze(0)\n        encoded_text_claim[\"token_type_ids\"] = encoded_text_claim[\"token_type_ids\"].squeeze(0)\n\n        ## Document Text\n        document_text = self.df['document'].iloc[idx]\n        if type(document_text) != str:\n          document_text = \" \"\n        encoded_text_document = self.tokenizer(\n            document_text, \n            add_special_tokens=True,\n            return_attention_mask=True, \n            pad_to_max_length=True, \n            max_length=64, \n            return_tensors='pt',\n            truncation=True\n        )\n        encoded_text_document[\"input_ids\"] = encoded_text_document[\"input_ids\"].squeeze(0)\n        encoded_text_document[\"attention_mask\"] = encoded_text_document[\"attention_mask\"].squeeze(0)\n        encoded_text_document[\"token_type_ids\"] = encoded_text_document[\"token_type_ids\"].squeeze(0)\n\n        # Label\n        if self.phase == 'test':\n          label = 0\n        else:\n          label = self.df['Category'].iloc[idx]\n          label = torch.tensor(label, dtype=torch.long)\n\n        inputs = {};\n        inputs[\"text\"] = (encoded_text_claim, encoded_text_document)\n        inputs[\"images\"] = (img_claim, img_document)\n        inputs[\"labels\"] = label\n\n        return inputs\n\n    def __len__(self):\n        return len(self.fnames)\n\ndef get_transforms(phase, mean, std):\n    list_transforms = []\n    \n    if phase == 'train':\n        list_transforms.extend(\n                  [\n                    #A.SmallestMaxSize(max_size=256),\n                    #A.ShiftScaleRotate(shift_limit=0.05, scale_limit=0.05, rotate_limit=10, p=0.5),\n                    #A.RandomCrop(height=256, width=256),\n                    A.RGBShift(r_shift_limit=15, g_shift_limit=15, b_shift_limit=15, p=0.5),\n                    #A.RandomBrightnessContrast(p=0.5),\n                    A.HorizontalFlip(),\n                    A.Rotate(limit=10,p=.5)\n                   ]\n        )\n    list_transforms.extend(\n        [ \n            A.Resize(256,256,interpolation = 1),\n            A.Normalize(mean=mean, std=std, p=1),\n            ToTensorV2(),\n        ]\n    )\n    list_trfms = A.Compose(list_transforms)\n    return list_trfms\ndef provider(\n    data_frame,\n    phase,\n    mean=None,\n    std=None,\n    batch_size=8,\n    num_workers=0,\n    split_size = 0.2\n):\n    '''Returns dataloader for the model training'''\n    if phase == \"test\":\n      df = data_frame\n    else:\n      label = data_frame['Category']\n      train_df, val_df = train_test_split(data_frame, test_size=split_size,stratify=label)\n      df = train_df if phase == \"train\" else val_df\n    image_dataset = Dataset(df, mean, std, phase)\n    is_train = False if phase == \"test\" else True\n    dataloader = DataLoader(\n        image_dataset,\n        batch_size=batch_size,\n        num_workers=num_workers,\n        pin_memory=False,\n        shuffle=False,   \n    )\n    return dataloader","metadata":{"execution":{"iopub.status.busy":"2021-11-10T18:34:12.770121Z","iopub.execute_input":"2021-11-10T18:34:12.770467Z","iopub.status.idle":"2021-11-10T18:34:12.794549Z","shell.execute_reply.started":"2021-11-10T18:34:12.770433Z","shell.execute_reply":"2021-11-10T18:34:12.793834Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_data_loader = provider(\n                test_df,\n                phase='test',\n                mean=(0.485, 0.456, 0.406),\n                std=(0.229, 0.224, 0.225),\n                batch_size=4,\n                num_workers=8,\n                split_size = 0.02\n            )","metadata":{"execution":{"iopub.status.busy":"2021-11-10T18:34:13.311113Z","iopub.execute_input":"2021-11-10T18:34:13.311843Z","iopub.status.idle":"2021-11-10T18:34:15.048941Z","shell.execute_reply.started":"2021-11-10T18:34:13.311796Z","shell.execute_reply":"2021-11-10T18:34:15.048161Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install efficientnet_pytorch","metadata":{"execution":{"iopub.status.busy":"2021-11-10T17:38:02.32202Z","iopub.execute_input":"2021-11-10T17:38:02.322293Z","iopub.status.idle":"2021-11-10T17:38:11.641669Z","shell.execute_reply.started":"2021-11-10T17:38:02.322246Z","shell.execute_reply":"2021-11-10T17:38:11.640829Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Model definition and training\n\nimport torch.nn as nn\nimport transformers\nfrom transformers import BertTokenizer, BertModel\nimport torch\nfrom efficientnet_pytorch import EfficientNet","metadata":{"execution":{"iopub.status.busy":"2021-11-10T18:34:16.372953Z","iopub.execute_input":"2021-11-10T18:34:16.373584Z","iopub.status.idle":"2021-11-10T18:34:16.37888Z","shell.execute_reply.started":"2021-11-10T18:34:16.373543Z","shell.execute_reply":"2021-11-10T18:34:16.378159Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Text_X2_Image_X2\n\nclass TwoInputTextModel(nn.Module):\n    def __init__(self, final_layer_size):\n        super().__init__()\n        self.tokenizer = transformers.BertTokenizer.from_pretrained(\n            \"bert-base-uncased\", do_lower_case=True\n        )\n        self.bert = transformers.BertModel.from_pretrained(\"bert-base-uncased\",\n                                                           return_dict=False)\n        self.bert_drop = nn.Dropout(0.1)\n        self.out1 = nn.Linear(768, final_layer_size)\n        self.norm = nn.BatchNorm1d(final_layer_size)\n    \n    def forward(self, inputs):\n        output = [None] * 2\n\n        _, bert_out1 = self.bert(**inputs[0])\n        bert_out1 = self.bert_drop(bert_out1)\n        output[0] = self.out1(bert_out1)\n        output[0] = self.norm(output[0])\n        \n        _, bert_out2 = self.bert(**inputs[1])\n        bert_out2 = self.bert_drop(bert_out2)\n        output[1] = self.out1(bert_out2)\n        output[1] = self.norm(output[1])\n        \n        return output\n\nclass TwoInputImgModel(nn. Module):\n    def __init__(self, hidden_layer_size):\n        super().__init__()\n        self.effnet = EfficientNet.from_pretrained('efficientnet-b3')\n        self._avg_pooling = nn.AdaptiveAvgPool2d(1)\n        self.drop = nn.Dropout(0.1)\n        self.dense_layer1 = nn.Linear(1536, hidden_layer_size)\n        self.norm2 = nn.BatchNorm1d(hidden_layer_size)\n\n    def forward(self, inputs):\n        output = [None] * 2\n        \n        eff_out1 = self.effnet.extract_features(inputs[0])\n        eff_out1 = nn.Flatten()(self._avg_pooling(eff_out1))\n        eff_out1 = self.drop(eff_out1)\n        output[0] = self.dense_layer1(eff_out1)\n        output[0] = self.norm2(output[0])\n        \n        eff_out2 = self.effnet.extract_features(inputs[1])\n        eff_out2 = nn.Flatten()(self._avg_pooling(eff_out2))\n        eff_out2 = self.drop(eff_out2)\n        output[1] = self.dense_layer1(eff_out2)\n        output[1] = self.norm2(output[1])\n        \n        return output\n\nclass BigModel(nn. Module):\n    def __init__(self, hidden_layer_size_text, hidden_layer_size_image, num_classes):\n        super().__init__()\n        self.image_model = TwoInputImgModel(hidden_layer_size_image)\n        self.text_model = TwoInputTextModel(hidden_layer_size_text)\n        self.dense1 = nn.Linear((hidden_layer_size_image)*2, 256)\n        self.dense2 = nn.Linear((hidden_layer_size_text)*2, 256)\n        self.norm1 = nn.BatchNorm1d(256)\n        self.norm2 = nn.BatchNorm1d(256)\n        self.out = nn.Linear(256*2, num_classes)\n    \n    def forward(self, inputs):\n        img_op1, img_op2 = self.image_model(inputs[\"images\"])\n        \n        text_op1, text_op2 = self.text_model(inputs[\"text\"])\n        \n        combined1 = torch.cat((img_op1.view(img_op1.size(0), -1),\n                               text_op1.view(img_op2.size(0), -1)),\n                              dim=1)\n        \n        combined2 = torch.cat((img_op2.view(img_op2.size(0),-1),\n                              text_op2.view(text_op2.size(0), -1)),\n                              dim=1)\n        \n        \n        combined1 = self.dense1(combined1)\n        combined1 = self.norm1(combined1)\n        \n        combined2 = self.dense2(combined2)\n        combined2 = self.norm2(combined2)\n        \n        combined = torch.cat((combined1.view(combined1.size(0),-1),\n                              combined2.view(combined2.size(0), -1)),\n                              dim=1)\n        \n        final_output = self.out(combined)\n        final_output = nn.Softmax()(final_output)\n        return final_output","metadata":{"execution":{"iopub.status.busy":"2021-11-10T18:34:24.183718Z","iopub.execute_input":"2021-11-10T18:34:24.184114Z","iopub.status.idle":"2021-11-10T18:34:24.205516Z","shell.execute_reply.started":"2021-11-10T18:34:24.184077Z","shell.execute_reply":"2021-11-10T18:34:24.204818Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Text_Image_X2\n\nclass TwoInputTextModel1(nn.Module):\n    def __init__(self, final_layer_size):\n        super().__init__()\n        self.tokenizer = transformers.BertTokenizer.from_pretrained(\n            \"bert-base-uncased\", do_lower_case=True\n        )\n        self.bert = transformers.BertModel.from_pretrained(\"bert-base-uncased\",\n                                                           return_dict=False)\n        self.bert_drop = nn.Dropout(0.1)\n        self.out1 = nn.Linear(768, final_layer_size)\n        self.norm = nn.BatchNorm1d(final_layer_size)\n    \n    def forward(self, inputs):\n        output = [None] * 2\n\n        _, bert_out1 = self.bert(**inputs[0])\n        bert_out1 = self.bert_drop(bert_out1)\n        output[0] = self.out1(bert_out1)\n        output[0] = self.norm(output[0])\n        \n        _, bert_out2 = self.bert(**inputs[1])\n        bert_out2 = self.bert_drop(bert_out2)\n        output[1] = self.out1(bert_out2)\n        output[1] = self.norm(output[1])\n        \n        return output\n\nclass TwoInputImgModel1(nn. Module):\n    def __init__(self, hidden_layer_size):\n        super().__init__()\n        self.effnet = EfficientNet.from_pretrained('efficientnet-b3')\n        self._avg_pooling = nn.AdaptiveAvgPool2d(1)\n        self.drop = nn.Dropout(0.1)\n        self.dense_layer1 = nn.Linear(1536, hidden_layer_size)\n        self.norm2 = nn.BatchNorm1d(hidden_layer_size)\n\n    def forward(self, inputs):\n        output = [None] * 2\n        \n        eff_out1 = self.effnet.extract_features(inputs[0])\n        eff_out1 = nn.Flatten()(self._avg_pooling(eff_out1))\n        eff_out1 = self.drop(eff_out1)\n        output[0] = self.dense_layer1(eff_out1)\n        output[0] = self.norm2(output[0])\n        \n        eff_out2 = self.effnet.extract_features(inputs[1])\n        eff_out2 = nn.Flatten()(self._avg_pooling(eff_out2))\n        eff_out2 = self.drop(eff_out2)\n        output[1] = self.dense_layer1(eff_out2)\n        output[1] = self.norm2(output[1])\n        \n        return output\n\nclass BigModel1(nn. Module):\n    def __init__(self, hidden_layer_size_text, hidden_layer_size_image, num_classes):\n        super().__init__()\n        self.image_model = TwoInputImgModel1(hidden_layer_size_image)\n        self.text_model = TwoInputTextModel1(hidden_layer_size_text)\n        self.dense1 = nn.Linear((hidden_layer_size_image)*2, 256)\n        self.dense2 = nn.Linear((hidden_layer_size_text)*2, 256)\n        self.norm1 = nn.BatchNorm1d(256)\n        self.norm2 = nn.BatchNorm1d(256)\n        self.out = nn.Linear(256*2, num_classes)\n    \n    def forward(self, inputs):\n        img_op1, img_op2 = self.image_model(inputs[\"images\"])\n        \n        text_op1, text_op2 = self.text_model(inputs[\"text\"])\n        \n        combined1 = torch.cat((img_op1.view(img_op1.size(0), -1),\n                               img_op2.view(img_op2.size(0), -1)),\n                              dim=1)\n        \n        combined2 = torch.cat((text_op1.view(text_op1.size(0),-1),\n                              text_op2.view(text_op2.size(0), -1)),\n                              dim=1)\n        \n        \n        combined1 = self.dense1(combined1)\n        combined1 = self.norm1(combined1)\n        \n        combined2 = self.dense2(combined2)\n        combined2 = self.norm2(combined2)\n        \n        combined = torch.cat((combined1.view(combined1.size(0),-1),\n                              combined2.view(combined2.size(0), -1)),\n                              dim=1)\n        \n        final_output = self.out(combined)\n        final_output = nn.Softmax()(final_output)\n        return final_output","metadata":{"execution":{"iopub.status.busy":"2021-11-10T18:35:45.034705Z","iopub.execute_input":"2021-11-10T18:35:45.035157Z","iopub.status.idle":"2021-11-10T18:35:45.055055Z","shell.execute_reply.started":"2021-11-10T18:35:45.035123Z","shell.execute_reply":"2021-11-10T18:35:45.054389Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class F1_Loss(nn.Module):\n    def __init__(self, epsilon=1e-7):\n        super().__init__()\n        self.epsilon = epsilon\n        \n    def forward(self, y_pred, y_true):\n        assert y_pred.ndim == 2\n        assert y_true.ndim == 1\n        y_true = F.one_hot(y_true, 5).to(torch.float32)\n        #y_pred = F.softmax(y_pred, dim=1)\n        \n        tp = (y_true * y_pred).sum(dim=0).to(torch.float32)\n        tn = ((1 - y_true) * (1 - y_pred)).sum(dim=0).to(torch.float32)\n        fp = ((1 - y_true) * y_pred).sum(dim=0).to(torch.float32)\n        fn = (y_true * (1 - y_pred)).sum(dim=0).to(torch.float32)\n\n        precision = tp / (tp + fp + self.epsilon)\n        recall = tp / (tp + fn + self.epsilon)\n\n        f1 = 2* (precision*recall) / (precision + recall + self.epsilon)\n        f1 = f1.clamp(min=self.epsilon, max=1-self.epsilon)\n        return 1- f1.mean()\n    \n    #def forward(self, y_pred, y_true):\n    #    return 1 - self.f1_score(y_pred, y_true);\n","metadata":{"execution":{"iopub.status.busy":"2021-11-10T18:35:45.620147Z","iopub.execute_input":"2021-11-10T18:35:45.620572Z","iopub.status.idle":"2021-11-10T18:35:45.630157Z","shell.execute_reply.started":"2021-11-10T18:35:45.620538Z","shell.execute_reply":"2021-11-10T18:35:45.629325Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tqdm import tqdm\n\nbatch_size = 4\ndef train_fn(data_loader, model, optimizer, device, scheduler):\n    model.train()\n    final_loss = 0\n    num_train_correct = 0\n    loader = tqdm(data_loader, total=len(data_loader))\n    total = 0;\n    for data in loader:#tqdm(data_loader, total=len(data_loader)):\n        for i in range(2):\n            for k, v in data[\"text\"][i].items():\n                data[\"text\"][i][k] = v.to(device)\n            data[\"images\"][i] = data[\"images\"][i].to(device) \n        optimizer.zero_grad()\n        op = model(data)\n        data[\"labels\"] = data[\"labels\"].to(device)\n        loss = F1_Loss().cuda()(op,data[\"labels\"])\n        loss.backward()\n        optimizer.step()\n#         scheduler.step(loss.item())\n        final_loss += loss.item()\n        total += 1\n        num_train_correct  += (op.max(1)[1] == data[\"labels\"]).sum().item()\n        loader.set_description(f\"loss - {final_loss/total}, acc - {num_train_correct/(total*batch_size)}\")\n    return final_loss / len(data_loader), num_train_correct/(len(data_loader)*batch_size)\n\ndef eval_fn(data_loader, model, device):\n    model.eval()\n    final_loss = 0\n    num_train_correct = 0\n    loader = tqdm(data_loader, total=len(data_loader))\n    total = 0;\n    for data in loader:#tqdm(data_loader, total=len(data_loader)):\n        for i in range(2):\n            for k, v in data[\"text\"][i].items():\n                data[\"text\"][i][k] = v.to(device)\n            data[\"images\"][i] = data[\"images\"][i].to(device)\n        op = model(data)\n        data[\"labels\"] = data[\"labels\"].to(device)\n        loss = F1_Loss()(op,data[\"labels\"])\n        final_loss += loss.item()\n        total += 1\n        num_train_correct  += (op.max(1)[1] == data[\"labels\"]).sum().item()\n        loader.set_description(f\"loss - {final_loss/total}, acc - {num_train_correct/(total*batch_size)}\")\n    return final_loss / len(data_loader), num_train_correct/(len(data_loader)*batch_size)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = BigModel(256,256,5)\nmodel1 = BigModel1(256,256,5)","metadata":{"execution":{"iopub.status.busy":"2021-11-10T18:36:04.923792Z","iopub.execute_input":"2021-11-10T18:36:04.924057Z","iopub.status.idle":"2021-11-10T18:36:14.31742Z","shell.execute_reply.started":"2021-11-10T18:36:04.924027Z","shell.execute_reply":"2021-11-10T18:36:14.316641Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"best_loss = np.inf\nbatch_size = 4\ndevice = \"cuda\"\nmodel_save_path = '.'\nmodel.to(device)\nmodel1.to(device)\nprint(\"Variables Defined\")","metadata":{"execution":{"iopub.status.busy":"2021-11-10T18:36:26.350422Z","iopub.execute_input":"2021-11-10T18:36:26.350687Z","iopub.status.idle":"2021-11-10T18:36:26.648697Z","shell.execute_reply.started":"2021-11-10T18:36:26.350657Z","shell.execute_reply":"2021-11-10T18:36:26.647946Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"param_optimizer = list(model.named_parameters())\nno_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\noptimizer_parameters = [\n        {\n            \"params\": [\n                p for n, p in param_optimizer if not any(nd in n for nd in no_decay)\n            ],\n            \"weight_decay\": 0.001,\n        },\n        {\n            \"params\": [\n                p for n, p in param_optimizer if any(nd in n for nd in no_decay)\n            ],\n            \"weight_decay\": 0.0,\n        },\n    ]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# num_train_steps = int((len(train_df)*0.8) / 4 * 1)\n# optimizer = AdamW(optimizer_parameters, lr=3e-2)\n# scheduler = get_linear_schedule_with_warmup(\n#         optimizer, num_warmup_steps=0, num_training_steps=num_train_steps\n#     )\n\noptimizer = optim.Adam(optimizer_parameters, lr=3e-3)\n        \nscheduler = ReduceLROnPlateau(optimizer,factor=0.33, mode=\"min\", patience=1, verbose=True)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"best_loss = np.inf\nmodel.to(\"cuda\")\nmodel.train()\nfor epoch in range(10):\n    train_loss,train_acc = train_fn(train_data_loader, model, optimizer, \"cuda\", scheduler)\n    test_loss,test_acc = eval_fn(val_data_loader, model, \"cuda\")\n    scheduler.step(test_loss)\n    if test_loss < best_loss:\n      best_loss = test_loss\n      torch.save(model, model_save_path + \"/val_loss:\" + str(test_loss) + \",epoch:\" + str(epoch) + \".pth\" )\n    print(f\"Train Loss = {train_loss} Train Acc = {train_acc} Valid Loss = {test_loss} Valid Acc = {test_acc}\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def test_fn(data_loader, model, device):\n    model.eval()\n    model1.eval()\n    out = []\n    final_loss = 0\n    num_train_correct = 0\n    for data in tqdm(data_loader, total=len(data_loader)):\n        for i in range(2):\n            for k, v in data[\"text\"][i].items():\n               data[\"text\"][i][k] = v.to(device)\n            data[\"images\"][i] = data[\"images\"][i].to(device)\n        op = model(data)\n        op1 = model1(data)\n        op1.to('cpu')\n        op.to('cpu')\n        op = op + op1\n        out.append(torch.max(op, 1)[1])\n    return out","metadata":{"execution":{"iopub.status.busy":"2021-11-10T18:39:25.105065Z","iopub.execute_input":"2021-11-10T18:39:25.105392Z","iopub.status.idle":"2021-11-10T18:39:25.113906Z","shell.execute_reply.started":"2021-11-10T18:39:25.105356Z","shell.execute_reply":"2021-11-10T18:39:25.112245Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"output = test_fn(test_data_loader, model, \"cuda\")","metadata":{"execution":{"iopub.status.busy":"2021-11-10T18:39:26.824938Z","iopub.execute_input":"2021-11-10T18:39:26.825206Z","iopub.status.idle":"2021-11-10T18:47:28.651016Z","shell.execute_reply.started":"2021-11-10T18:39:26.825179Z","shell.execute_reply":"2021-11-10T18:47:28.650139Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions = []\nfor x in output:\n  predictions.extend(x.cpu().detach().numpy())\nanswer = pd.DataFrame(predictions, columns =['Category'])","metadata":{"execution":{"iopub.status.busy":"2021-11-10T18:47:28.656562Z","iopub.execute_input":"2021-11-10T18:47:28.656775Z","iopub.status.idle":"2021-11-10T18:47:28.715136Z","shell.execute_reply.started":"2021-11-10T18:47:28.656749Z","shell.execute_reply":"2021-11-10T18:47:28.714508Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"answer.Category = answer.Category.map(ind_to_category)","metadata":{"execution":{"iopub.status.busy":"2021-11-10T18:47:28.727917Z","iopub.execute_input":"2021-11-10T18:47:28.728303Z","iopub.status.idle":"2021-11-10T18:47:28.737079Z","shell.execute_reply.started":"2021-11-10T18:47:28.728215Z","shell.execute_reply":"2021-11-10T18:47:28.736326Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"answer.to_csv(\"answer.csv\")","metadata":{"execution":{"iopub.status.busy":"2021-11-10T18:48:22.758593Z","iopub.execute_input":"2021-11-10T18:48:22.758862Z","iopub.status.idle":"2021-11-10T18:48:22.78373Z","shell.execute_reply.started":"2021-11-10T18:48:22.758834Z","shell.execute_reply":"2021-11-10T18:48:22.783061Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}